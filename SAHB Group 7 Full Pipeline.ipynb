{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def split_wav(input_path, output_dir, chunk_duration=10):\n",
    "    \"\"\"\n",
    "    Splits a WAV file into fixed-size chunks (e.g., 10 seconds each).\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load audio file\n",
    "    data, sr = sf.read(input_path)\n",
    "\n",
    "    samples_per_chunk = int(chunk_duration * sr)\n",
    "    total_samples = len(data)\n",
    "\n",
    "    # Number of chunks\n",
    "    num_chunks = int(np.ceil(total_samples / samples_per_chunk))\n",
    "\n",
    "    # Base name for output files\n",
    "    basename = os.path.splitext(os.path.basename(input_path))[0]\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * samples_per_chunk\n",
    "        end = min(start + samples_per_chunk, total_samples)\n",
    "\n",
    "        chunk = data[start:end]\n",
    "\n",
    "        out_file = os.path.join(output_dir, f\"{basename}_chunk_{i+1}.wav\")\n",
    "\n",
    "        # Save chunk\n",
    "        sf.write(out_file, chunk, sr)\n",
    "        print(f\"Saved: {out_file}\")\n",
    "\n",
    "\n",
    "#Path to input WAV file and output folder\n",
    "input_wav_path = r\"/Users/ian.straits/Documents/Graduate School/SAHB/data1-08.wav\"\n",
    "output_folder   = r\"/Users/ian.straits/Documents/Graduate School/SAHB/Audio8\"\n",
    "\n",
    "# Split into 10-second chunks\n",
    "split_wav(input_wav_path, output_folder, chunk_duration=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa pandas scikit-learn joblib soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b84b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Manual Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "AUDIO_DIR = \"/Users/ian.straits/Documents/Graduate School/SAHB/Attempt 1/All Chunks\"\n",
    "LABELS_CSV = \"/Users/ian.straits/Documents/Graduate School/SAHB/Attempt 1/LabelsCombined.csv\"\n",
    "\n",
    "df = pd.read_csv(LABELS_CSV)\n",
    "print(df.head())\n",
    "print(\"Number of manually labeled files:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6495fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction Function (Log-Mel Spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, sr_target=16000, n_mels=64, duration=None):\n",
    "    \"\"\"\n",
    "    Returns a 1D audio feature vector based on log-mel spectrogram.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr_target, mono=True, duration=duration)\n",
    "        if len(y) == 0:\n",
    "            return None\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr_target, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Statistical features across time\n",
    "        mean = S_db.mean(axis=1)\n",
    "        std = S_db.std(axis=1)\n",
    "\n",
    "        # Combine into one feature vector (length = 2 * n_mels)\n",
    "        feat = np.concatenate([mean, std], axis=0)\n",
    "        return feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Training Data from Manual Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "missing = 0\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    fname = row[\"filename\"]\n",
    "    label = row[\"label\"]\n",
    "\n",
    "    file_path = os.path.join(AUDIO_DIR, fname)\n",
    "    if not os.path.exists(file_path):\n",
    "        missing += 1\n",
    "        continue\n",
    "\n",
    "    feat = extract_features(file_path)\n",
    "    if feat is None:\n",
    "        continue\n",
    "\n",
    "    X.append(feat)\n",
    "    y.append(int(label))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Feature matrix:\", X.shape)\n",
    "print(\"Labels:\", y.shape)\n",
    "print(\"Missing files:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split + Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features (helps with generalization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Model and Scaler\n",
    "\n",
    "joblib.dump(clf, \"construction_classifier.joblib\")\n",
    "joblib.dump(scaler, \"feature_scaler.joblib\")\n",
    "print(\"Model + scaler saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"construction_classifier.joblib\")\n",
    "scaler = joblib.load(\"feature_scaler.joblib\")\n",
    "\n",
    "all_files = sorted([f for f in os.listdir(AUDIO_DIR) if f.lower().endswith(\".wav\")])\n",
    "\n",
    "manual_dict = {row[\"filename\"]: str(row[\"label\"]) for _, row in df.iterrows()}\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for fname in all_files:\n",
    "    file_path = os.path.join(AUDIO_DIR, fname)\n",
    "\n",
    "    # if fname in manual_dict:\n",
    "    #     # keep human label\n",
    "    #     final_results.append({\n",
    "    #         \"filename\": fname,\n",
    "    #         \"label\": int(manual_dict[fname]),\n",
    "    #         \"source\": \"manual\", \n",
    "    #         \"probability\": float(manual_dict[fname])\n",
    "    #     })\n",
    "    #     continue\n",
    "\n",
    "    # Predict using model\n",
    "    feat = extract_features(file_path)\n",
    "    if feat is None:\n",
    "        continue\n",
    "\n",
    "    feat_scaled = scaler.transform([feat])\n",
    "    prob = clf.predict_proba(feat_scaled)[0][1]\n",
    "    pred = int(clf.predict(feat_scaled)[0])\n",
    "\n",
    "    if fname in manual_dict:\n",
    "        # keep human label\n",
    "        final_results.append({\n",
    "            \"filename\": fname,\n",
    "            \"label\": pred,\n",
    "            \"source\": \"manual\", \n",
    "            \"probability\": prob\n",
    "        })\n",
    "    else:\n",
    "        final_results.append({\n",
    "            \"filename\": fname,\n",
    "            \"label\": pred,\n",
    "            \"source\": \"model\", \n",
    "            \"probability\": prob\n",
    "        })\n",
    "        \n",
    "\n",
    "    final_results.append({\n",
    "        \"filename\": fname,\n",
    "        \"label\": pred,\n",
    "        \"source\": \"model\", \n",
    "        \"probability\": prob\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(final_results)\n",
    "print(\"Total labeled files:\", len(final_df))\n",
    "\n",
    "final_df.to_csv(\"labels_full_with_source.csv\", index=False)\n",
    "print(\"Saved --> labels_full_with_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean version without the source column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa46866",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[[\"filename\", \"label\", \"probability\"]].to_csv(\"labels_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual labeling tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f83600",
   "metadata": {},
   "outputs": [],
   "source": [
    "testprobs = clf.predict_proba(X_test_scaled)[:,1]\n",
    "print (testprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testprobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainprobs = clf.predict_proba(X_train_scaled)[:,1]\n",
    "print (trainprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainprobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6072587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b65ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_csv(\"labels_full_with_source.csv\")\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e95ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(read_df), 2):\n",
    "    curr_prob = read_df.loc[i, \"probability\"]\n",
    "    read_df.loc[i, \"probability\"] = 1-curr_prob\n",
    "    df = pd.concat([df, read_df.loc[[i]]])\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59615616",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_df = pd.read_csv(\"tod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a214d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TOD\"] = tod_df[\"TOD\"]\n",
    "df[\"smoothed probabilities\"] = 0.0\n",
    "df[\"WNA setting\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14101add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(curr_prob, prev_ema, hp):\n",
    "    return (curr_prob*hp) + (prev_ema*(1-hp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_hyperparamater = 0.3\n",
    "hysteresis_low_thresh = 0.15\n",
    "hysteresis_high_thresh = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if i == 0:\n",
    "        curr_prob = df.loc[i, \"probability\"]\n",
    "        df.loc[i, \"smoothed probabilities\"] = curr_prob\n",
    "        if curr_prob < hysteresis_high_thresh:\n",
    "            df.loc[i, \"WNA setting\"] = \"NO\"\n",
    "        else:\n",
    "            df.loc[i, \"WNA setting\"] = \"YES\"\n",
    "    else:\n",
    "        prev_ema = ema(df.loc[i, \"probability\"], df.loc[i-1, \"smoothed probabilities\"], ema_hyperparamater)\n",
    "        df.loc[i, \"smoothed probabilities\"] = prev_ema\n",
    "        if prev_ema <= hysteresis_low_thresh:\n",
    "            df.loc[i, \"WNA setting\"] = \"NO\"\n",
    "        elif prev_ema >= hysteresis_high_thresh:\n",
    "            df.loc[i, \"WNA setting\"] = \"YES\"\n",
    "        else:\n",
    "            df.loc[i, \"WNA setting\"] = df.loc[i-1, \"WNA setting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e96d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"white_noise_actuator_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5597de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"/Users/ian.straits/Documents/Graduate School/SAHB/Attempt 1/All Chunks\"\n",
    "\n",
    "# List of the four chunks + titles\n",
    "examples = [\n",
    "    (\"data1-05_chunk_916.wav\", \"Nighttime (Label 1)\"),\n",
    "    (\"data1-07_chunk_687.wav\", \"Reverse Alarm (Label 0)\"),\n",
    "    (\"data1-07_chunk_322.wav\", \"Hammer (Label 0)\"),\n",
    "    (\"data1-07_chunk_560.wav\", \"Emergency Siren (Label 0)\"),\n",
    "]\n",
    "\n",
    "# Make fonts a bit bigger globally\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharey=True)\n",
    "axes_flat = axes.ravel()\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for ax, (fname, title) in zip(axes_flat, examples):\n",
    "    path = os.path.join(AUDIO_DIR, fname)\n",
    "    print(\"Loading:\", path)\n",
    "\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(path, sr=None, mono=True)\n",
    "\n",
    "    # Mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Plot\n",
    "    img = librosa.display.specshow(\n",
    "        S_db,\n",
    "        sr=sr,\n",
    "        x_axis=\"time\",\n",
    "        y_axis=\"mel\",\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    imgs.append(img)\n",
    "\n",
    "# Only label left and bottom axes to avoid clutter\n",
    "axes[1, 0].set_xlabel(\"Time (s)\", fontsize=12)\n",
    "axes[1, 1].set_xlabel(\"Time (s)\", fontsize=12)\n",
    "axes[0, 0].set_ylabel(\"Mel frequency (Hz)\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Mel frequency (Hz)\", fontsize=12)\n",
    "\n",
    "# Add extra space at bottom for horizontal colorbar\n",
    "plt.subplots_adjust(bottom=-0.15)\n",
    "\n",
    "# One horizontal colorbar below all four plots\n",
    "cbar = fig.colorbar(\n",
    "    imgs[0],\n",
    "    ax=axes_flat,\n",
    "    orientation=\"horizontal\",\n",
    "    fraction=0.05,\n",
    "    pad=0.18\n",
    ")\n",
    "cbar.set_label(\"Amplitude (dB)\", fontsize=12)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf93194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = \"/Users/ian.straits/Documents/Graduate School/SAHB/Attempt 1/labels_full_with_source_edit.csv\"   # change if needed\n",
    "\n",
    "# 1. Load CSV, ignore weird encoding issues from Excel\n",
    "df = pd.read_csv(CSV_PATH, encoding_errors=\"ignore\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# 2. Convert TOD column (like \"11:30:00 AM\") to datetime\n",
    "df[\"TOD\"] = pd.to_datetime(df[\"TOD\"], format=\"%I:%M:%S %p\")\n",
    "\n",
    "# 3. Keep only rows where Label == 0\n",
    "df_zero = df[df[\"Label\"] == 0]\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Rows with Label = 0: {len(df_zero)}\")\n",
    "\n",
    "# 4. Plot histogram of TOD for Label = 0\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(df_zero[\"TOD\"], bins=50)\n",
    "\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Count of Label = 0\")\n",
    "plt.title(\"Label = 0 (construction) vs Time of Day\")\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"white_noise_actuator_results.csv\")\n",
    "df['TOD'] = pd.to_datetime(df['TOD'], format='%I:%M:%S %p')\n",
    "df['WNA_numeric'] = df['WNA setting'].map({'YES': 1, 'NO': 0})\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "\n",
    "ax1.scatter(df['TOD'], df['WNA_numeric'], color='red', s=2)\n",
    "ax1.set_ylim(-0.1, 1.1)\n",
    "ax1.set_yticks([0,1])\n",
    "ax1.set_yticklabels(['OFF','ON'])\n",
    "ax1.set_xlabel(\"Hour of Day\")\n",
    "ax1.set_ylabel(\"White Noise Actuator\")\n",
    "\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax1.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45)\n",
    "print(ax1.get_xticklabels())\n",
    "\n",
    "df0 = df[df[\"label\"] == 0].copy()\n",
    "df0['hour'] = df0['TOD'].dt.hour\n",
    "counts0 = df0.groupby('hour').size()\n",
    "counts0 = counts0.reindex(range(24), fill_value=0)\n",
    "\n",
    "start_date = df['TOD'].dt.normalize().iloc[0]\n",
    "hist_hours = [start_date + pd.Timedelta(hours=h) for h in counts0.index]\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(hist_hours, counts0.values, width=pd.Timedelta(minutes=60), color='skyblue', align='edge', alpha=0.3)\n",
    "ax2.set_ylabel(\"Construction Data Point Frequency\")\n",
    "\n",
    "ax1.set_title(\"White Noise Actuator ON/OFF Over Time\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
